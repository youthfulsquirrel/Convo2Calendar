{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d92248eec045978cc2e3bf0f2e144f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4e317bfa9c43c097da2df9dd8b2221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, you need an access token\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,)\n",
    "\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "# enable evaluation mode to allow model inference\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    ")\n",
    "\n",
    "stop_list = ['\\nHuman:', '\\n```\\n']\n",
    "\n",
    "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
    "stop_token_ids\n",
    "\n",
    "import torch\n",
    "\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
    "stop_token_ids\n",
    "\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])\n",
    "\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMeeting Transcript\\n\\nDate: 2023-10-13\\n\\nTime: 11:27 PST\\n\\nAttendees:\\n\\nJohn Doe, Design Lead\\nJane Smith, Designer\\nMary Green, Designer\\nJohn Doe: Alright, everyone, let's get started. Today, we're going to be discussing the green building design concept that Jane has developed.\\n\\nJane Smith: Thank you, John. Here's a summary of my concept:\\n\\nThe building will be designed to maximize natural light and ventilation.\\nWe will use renewable energy sources, such as solar panels and wind turbines.\\nWe will use sustainable materials, such as recycled wood and bamboo.\\nWe will incorporate water conservation features, such as rainwater harvesting and low-flow toilets.\\nJohn Doe: That sounds great, Jane. I'm really impressed with the concept.\\n\\nMary Green: Me too. I think it's a very innovative and sustainable design.\\n\\nJohn Doe: However, I have one concern: cost. I'm worried that the cost of implementing all of these green features will be too high.\\n\\nJane Smith: I understand your concern. However, I believe that the long-term savings from these green features will outweigh the upfront cost. For example, the solar panels will generate electricity, which will reduce our reliance on the grid. The water conservation features will reduce our water bill. And the sustainable materials will last longer than traditional materials, which will reduce our maintenance costs.\\n\\nJohn Doe: That's a good point. I think we need to do some more research to get a better idea of the cost of implementing all of these green features.\\n\\nJane Smith: I agree.\\n\\nJohn Doe: Okay, then. Here's what I propose:\\n\\nJane and Mary, you will be responsible for researching the cost of implementing the green features that you have proposed. Update the team in 2 weeks.\\nI will be responsible for researching vendors who can provide these green features. I'll update you guys by 16 Oct.\\nJane Smith: Sounds good.\\n\\nMary Green: Me too.\\n\\nJane Smith: Perfect.\\n\\nMary Green: Sounds good.\\n\\nEnd Time: 14:27 PST\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../transcripts/meeting002.txt\") as f:\n",
    "    transcript_str = f.read()\n",
    "\n",
    "print(transcript_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "meeting_date = ResponseSchema(\n",
    "        name=\"meeting_date\",\n",
    "        description=\"date of the meeting stored in datetime format DD/MM/YYYY.\",\n",
    "    )\n",
    "attendees_list = ResponseSchema(\n",
    "        name=\"attendees_list\",\n",
    "        description=\"Full name of everyone present in the meeting, each stored as a string in the list.\",\n",
    "    )\n",
    "\n",
    "start_time = ResponseSchema(\n",
    "        name=\"start_time\",\n",
    "        description=\"time the meeting started in 24 hour HH:mm format in datetime\",\n",
    "    )\n",
    "\n",
    "end_time = ResponseSchema(\n",
    "        name=\"end_time\",\n",
    "        description=\"time the meeting ended in 24 hour HH:mm format in datetime\",\n",
    "    )\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [meeting_date, attendees_list, start_time, end_time]\n",
    ")\n",
    "\n",
    "response_format = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"You are a helpful formatting assistant. Return the meeting_date, attendees_list, start_time, end_time separately. '''{meeting_info}''' \\n {format_instructions}\")\n",
    "\n",
    "llm_openai = OpenAI()\n",
    "formated_prompt = prompt.format(**{\"meeting_info\":transcript_str, \"format_instructions\":output_parser.get_format_instructions()})\n",
    "response_openai = llm_openai(formated_prompt)\n",
    "# print(response_openai)\n",
    "# print('printing response')\n",
    "meeting_info_dict = output_parser.parse(response_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_date': '2023-10-13',\n",
       " 'attendees_list': ['John Doe', 'Jane Smith', 'Mary Green'],\n",
       " 'start_time': '11:27 PST',\n",
       " 'end_time': '14:27 PST'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "text_chunks = text_splitter.split_documents(TextLoader(\"transcripts/meeting002.txt\").load())\n",
    "\n",
    "\n",
    "model_name = [\"sentence-transformers/all-mpnet-base-v2\", 'sentence-transformers/all-MiniLM-L6-v2', \"sentence-transformers/paraphrase-MiniLM-L6-v2\"]\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name[1],model_kwargs={'device': 'cuda'})\n",
    "vectorstore=FAISS.from_documents(text_chunks, embeddings)\n",
    "\n",
    "llm=HuggingFacePipeline(pipeline=generate_text, model_kwargs={'temperature':0})\n",
    "chain =  RetrievalQA.from_chain_type(llm=llm, chain_type = \"stuff\",return_source_documents=False, retriever=vectorstore.as_retriever())\n",
    "query_list = [ \"you are a helpful AI meeting minute writer. Help me to write a meeting summary in prose, detailing all the important tasks mentioned, especially the people in charge of each task and the respective deadlines if any. Your minute should be ordered based on the topics discussed and not on chronological order.\"]\n",
    "chat_history = []\n",
    "for query in query_list:\n",
    "    result = chain({\"query\": query, \"chat_history\": chat_history})\n",
    "    #chat_history.append((query, result[\"result\"].strip(\"\\n\")))\n",
    "    result=chain({\"query\": query, \"chat_history\": []},return_only_outputs=True)\n",
    "    print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure! Based on the transcript provided, here is a meeting summary in prose:\\n\\nThe meeting began with a discussion of the green building design concept developed by Jane Smith. John Doe expressed his appreciation for the concept, but also raised concerns about the cost of implementing the green features. To address this concern, Jane suggested doing further research on the cost of the green features and updating the team in two weeks.\\n\\nJohn Doe then assigned tasks to the team members. He asked Jane and Mary to research the cost of implementing the green features and update the team in two weeks. He also asked Jane to research vendors who could provide the green features and update the team by October 16th.\\n\\nIn conclusion, the meeting assigned specific tasks to team members and set deadlines for their completion. Jane was responsible for researching the cost of the green features, while John was responsible for researching vendors who could provide them. Both were given deadlines of October 16th and two weeks prior to that date, respectively.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "with open(r'archive_note.txt', 'r') as fp:\n",
    "    # read all lines using readline()\n",
    "    lines = fp.readlines()\n",
    "    for line in lines:\n",
    "        os.environ['OPENAI_API_KEY'] = line\n",
    "\n",
    "main_topics = ResponseSchema(\n",
    "        name=\"task_description\",\n",
    "        description=\"Describe each task in detail and store it as a string in the list.\",\n",
    "    )\n",
    "deadline = ResponseSchema(\n",
    "        name=\"deadline\",\n",
    "        description=\"The deadline of the corresponding task_description, stored as a unique string in the list, in the same order as it appears in task_description.\",\n",
    "    )\n",
    "\n",
    "person_in_charge = ResponseSchema(\n",
    "        name=\"person_in_charge\",\n",
    "        description=\"default str is NA. The people in involved in each task, who needs to perform follow-up actions after the meeting or had presented this task in the meeting, stored as a string in the list, in the same order as it appears in task_description.\",\n",
    "    )\n",
    "\n",
    "days_left = ResponseSchema(\n",
    "        name=\"days_left\",\n",
    "        description=\"Optional parameter, default value is int 0. If the deadline given is relative from the date of the meeting, store as an int (the number of days given) in the list, in the same order as it appears in task_description.\",\n",
    "    )\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(\n",
    "    [main_topics, deadline, person_in_charge, days_left]\n",
    ")\n",
    "\n",
    "response_format = output_parser.get_format_instructions()\n",
    "print(response_format)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"You are a helpful formatting assistant. The meeting transcript is delimited with triple backticks. It is already a summarised version, hence you don't need to summarise it further when providing task_description. A task can be what team members have presented in the meeting, or follow-up actions required after this meeting. Return the task_description, and their respective deadline, person_in_charge and days_left separately. '''{meeting_transcript}''' \\n {format_instructions}\")\n",
    "\n",
    "\n",
    "llm_openai = OpenAI()\n",
    "\n",
    "meeting_transcript = result['result']\n",
    "\n",
    "formated_prompt = prompt.format(**{\"meeting_transcript\":meeting_transcript, \"format_instructions\":output_parser.get_format_instructions()})\n",
    "response_openai = llm_openai(formated_prompt)\n",
    "print(response_openai[:5])\n",
    "print(type(response_openai))\n",
    "print(response_openai)\n",
    "\n",
    "if response_openai[0] == '[':\n",
    "    print('error in',response_openai )\n",
    "    response_openai = response_openai[1:-2]\n",
    "    print('re-attempt with',response_openai )\n",
    "print('printing response')\n",
    "formatted_output = output_parser.parse(response_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n```json\\n{\\n\\t\"meeting_date\": \"2023-10-13\",\\n\\t\"attendees_list\": [\"John Doe\", \"Jane Smith\", \"Mary Green\"],\\n\\t\"start_time\": \"11:27 PST\",\\n\\t\"end_time\": \"14:27 PST\"\\n}\\n```'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(response_openai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_description': ['Research the cost of implementing the green features and update the team in two weeks',\n",
       "  'Research vendors who could provide the green features and update the team by October 16th'],\n",
       " 'deadline': ['Two weeks', 'October 16th'],\n",
       " 'person_in_charge': ['Jane and Mary', 'Jane'],\n",
       " 'days_left': [14, 16]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_content = []\n",
    "for i in range (len(formatted_output['task_description'])):\n",
    "    mydict = {}\n",
    "    mydict['task_description'] = formatted_output['task_description'][i]\n",
    "    info_list = [formatted_output['deadline'][i],formatted_output['person_in_charge'][i]]\n",
    "    mydict['additional info'] = info_list\n",
    "    table_content.append(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_description': 'Research the cost of implementing the green features and update the team in two weeks',\n",
       "  'additional info': ['Two weeks', 'Jane and Mary']},\n",
       " {'task_description': 'Research vendors who could provide the green features and update the team by October 16th',\n",
       "  'additional info': ['October 16th', 'Jane']}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_date': '2023-10-13',\n",
       " 'attendees_list': 'John Doe\\nJane Smith\\nMary Green',\n",
       " 'start_time': '11:27 PST',\n",
       " 'end_time': '14:27 PST',\n",
       " 'col_labels': ['Deadline', 'Person-In-Charge'],\n",
       " 'tbl_contents': [{'task_description': 'Research the cost of implementing the green features and update the team in two weeks',\n",
       "   'additional info': ['Two weeks', 'Jane and Mary']},\n",
       "  {'task_description': 'Research vendors who could provide the green features and update the team by October 16th',\n",
       "   'additional info': ['October 16th', 'Jane']}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = meeting_info_dict.copy()\n",
    "context['attendees_list'] =  '\\n'.join(meeting_info_dict['attendees_list'])\n",
    "context['col_labels'] = ['Deadline', 'Person-In-Charge']\n",
    "context['tbl_contents'] = table_content\n",
    "print(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
